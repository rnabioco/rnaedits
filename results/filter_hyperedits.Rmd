---
title: "Filter hyperedited reads"
author: "Kent Riemondy RBI"
date: "11/7/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(cache = TRUE)
```

```{r ,message=FALSE, warning=FALSE, cache = F}
source("globals.R")
library()
library(scales)
```


## Hyperediting Detection

A-to-I editing can edit messages so extensively that cDNAs no longer map to the reference genome. To identify these editing events, one can mask all A nucleotides to G's in the unmapped reads and genome, and remap. The original sequences of the reference and reads can then be analysed to determine the number of mismatches (of A to G type). By applying some basic filters, one can enrich for bona fide hyperediting events. The methods are described in:

>A genome-wide map of hyper-edited RNA reveals numerous new sites. Porath H., et all Nature Communications 2014.

I applied the methods from Porath et al. to the hibernation RNA-Seq data by writing a few C++ and Python scripts. The authors provided a pipeline, but it was difficult to use (written in bash) and wouldn't work well on tesla. The final output of these scripts are two bed files per fastq files, one containing hyper-editing regions found in each read and one containing an interval for each editing site found. 

Next I will produce some summary figures to determine if hyper-edited sites are enriched in Torpid and Early Arousal Animals, similar to observations from editing sites derived from tradiional variant calling.

## Edited Reads

First I'll analyze the distibutions of hyperedited clusters. A cluster is the contiguous region of high density editing found within each read. Clusters are merged if overlapping from the sample brain region and hibernation state. 

Shown first is the number of unique reads (defined by chrom start end and strand). 

```{r alleles}
alleles  <- list(
              "A_to_C",
              "A_to_G",
              "A_to_T",
              "C_to_A",
              "C_to_G",
              "C_to_T",
              "G_to_A",
              "G_to_C",
              "G_to_T",
              "T_to_A",
              "T_to_C",
              "T_to_G")
```

```{r load_dat, cache = F, message = F, warning = F, fig.width = 8, fig.height = 20}

read_hyperedits <- function(allele, type = "reads"){
  # first load in bed files of individual hyperedited reads
  files <- dir(file.path(data_dir, "hyperedits", "bed",
                     type, "filtered", allele),
           pattern = "*.bed", 
           recursive = T,
           full.names = T)
  
  dat <- map(files, ~read_tsv(.x, col_names = c("chrom",
                                                "start",
                                                "end",
                                                "id",
                                                "mismatches",
                                                "strand"), 
                              col_types = c("cddccc")))
  file_ids <- basename(files)
  regions <- str_extract(files, "medulla|brainrest|hypothalamus")
  file_names <- str_c(file_ids, ":::", regions)
  names(dat) <- file_names
  
  dat <- bind_rows(dat, .id = "name")
  # exit if no sites/reads exist
  if (nrow(dat) == 0){ return(NULL) }
  
  dat <- separate(dat, name, c("fileid", "region"), ":::")
  dat <- mutate(dat,
                animal_number = str_split(fileid, "_", simplify = T)[, 1],
                animal_number = str_replace(animal_number, "^[0-9]+-", ""))
  #annotate with State
  
  pdata <- readr::read_tsv(file.path(docs_dir, "BrainRegionRNAseqLibMetadata.txt"))
  pdata <- gather(pdata, region, sample, Forebrain, Hypothalamus, Medulla)
  pdata <- mutate(pdata, 
                  animal_number = str_split(sample, "_", simplify = T)[, 1])
  simple_pdata <- pdata %>% 
    dplyr::select(State, animal_number)
  
  dat <- left_join(dat, 
                   simple_pdata, 
                   by ="animal_number")
  
  dat <- mutate(dat, 
                   region = ifelse(region == "brainrest",
                                   "Forebrain",
                                   ifelse(region == "medulla",
                                          "Medulla",
                                          ifelse(region == "hypothalamus",
                                                 "Hypothalamus",
                                                 NA))))
  
  dat
}

read_dat <- map(alleles, ~read_hyperedits(.x))
names(read_dat) <- alleles
read_dat <- bind_rows(read_dat, .id ="allele")

summary_dat <- group_by(read_dat, allele, region, State) %>% 
  dplyr::select("chrom", "start", "end", "strand") %>% 
  unique() %>% 
  summarize(unique_sites = n()) %>% 
  ungroup()

summary_dat <- mutate(summary_dat, 
                            State = factor(State,
                                           levels = state_order),
                      allele = str_replace(allele, "_to_", "->"))

ggplot(summary_dat, aes(State, unique_sites)) +
  geom_bar(stat = "identity", aes(fill = State)) +
  scale_fill_manual(values = state_cols) +
  ylab("Unique hyperedited reads") +
  facet_grid(allele~region) +
  theme(
    axis.text.x = element_text(colour = state_cols)
  )
```

Overall it looks like what we expect, with more hyperedited reads associated with the LT and Ar samples. 

Next shown is the total number of reads for each variant type. A to G clearly dominates with 84% of the hyperedited reads being A to G type. This is a nice result as it suggests that we can use the hyperedited sites found in the non-LT and non-Ar samples as a background non-cold enriched set of editing sites for structural analysis. 

```{r}
summary_all_data <- group_by(read_dat, allele) %>% 
  dplyr::select("chrom", "start", "end", "strand") %>% 
  unique() %>% 
  summarize(unique_sites = n()) %>% 
  ungroup()

summary_all_data <- mutate(summary_all_data,
                      allele = str_replace(allele, "_to_", "->"))

summary_all_data %>% 
  group_by(allele) %>% 
  summarize(total = sum(unique_sites, na.rm = T)) -> all_regions

p <- ggplot(all_regions, aes(allele, total)) +
  geom_bar(stat = "identity") +
  scale_fill_manual() +
  scale_y_continuous(labels = comma) +
  ylab("Unique hyperedited reads") +
  theme(
    axis.title.x = element_blank(),
    axis.text.x = element_text(angle = 90,
                                 hjust = 1, vjust = 0.5),
    legend.title = element_blank()
    )
p

all_regions %>% 
  ungroup() %>% 
  mutate(total_sites = sum(total),
         percent_hyperedited_sites = 100 * total / total_sites)

```

Next all overlapping hyperedited regions will be merged per state and region and similar plots will be generated. 
```{r merge_regions, eval = T}

read_dat %>% 
  group_by(region, State, allele, strand) %>% 
  bed_merge(., read_count = n()) -> merged_read_dat

merged_read_dat %>% 
  group_by(chrom, start, end, strand, add = T) %>% 
  summarize(read_count = sum(read_count),
            cluster_length = max(end) - min(start)) -> merged_read_dat


merged_read_dat <- mutate(ungroup(merged_read_dat), 
                            State = factor(State,
                                           levels = state_order))

dplyr::filter(merged_read_dat, allele == "A_to_G") -> AG_merged_read_dat

ggplot(AG_merged_read_dat, aes(State, cluster_length)) +
  geom_boxplot() + 
  facet_wrap(~region) +
  ylab("edited cluster length") +
  theme(
    axis.text.x = element_text(colour = state_cols)
  )


summary_dat <- mutate(merged_read_dat, 
                            State = factor(State,
                                           levels = state_order),
                      allele = str_replace(allele, "_to_", "->"))

# regions merged by State, allele, and region
ggplot(summary_dat, aes(State)) +
  geom_bar(aes(fill = State)) +
  scale_fill_manual(values = state_cols) +
  ylab("Unique hyperedited regions") +
  facet_grid(allele~region) +
  theme(
    axis.text.x = element_text(colour = state_cols)
  )

# distribution across A_to_G alleles across states
summary_dat %>% 
  dplyr::filter(allele == "A->G") -> A_G_summary_dat

ggplot(A_G_summary_dat, aes(State)) +
  geom_bar(aes(fill = State)) +
  scale_fill_manual(values = state_cols) +
  ylab("Unique hyperedited regions") +
  labs(title = "A to G hyperedited regions") + 
  facet_grid(~region) +
  theme(
    axis.text.x = element_blank()
  )


```

## Editing Sites

Next, the indidividual editing sites will be quantified similar to above. 

```{r load_edits, message = F, fig.width = 8, fig.height = 20}

edit_dat <- map(alleles, ~read_hyperedits(.x, type = "edits"))
names(edit_dat) <- alleles
edit_dat <- bind_rows(edit_dat, .id ="allele")

summary_dat <- group_by(edit_dat, allele, region, State) %>% 
  dplyr::select("chrom", "start", "end", "strand") %>% 
  unique() %>% 
  summarize(unique_sites = n()) %>% 
  ungroup()

summary_dat <- mutate(summary_dat, 
                            State = factor(State,
                                           levels = state_order),
                      allele = str_replace(allele, "_to_", "->"))

p <- ggplot(summary_dat, aes(State, unique_sites)) +
  geom_bar(stat = "identity", aes(fill = State)) +
  scale_fill_manual(values = state_cols) +
  ylab("Unique hyperedited sites") +
  facet_grid(allele~region) +
  theme(
    axis.text.x = element_text(colour = state_cols)
  )
p
```

```{r}
summary_all_data <- group_by(edit_dat, allele) %>% 
  dplyr::select("chrom", "start", "end", "strand") %>% 
  unique() %>% 
  summarize(unique_sites = n()) %>% 
  ungroup()

summary_all_data <- mutate(summary_all_data,
                      allele = str_replace(allele, "_to_", "->"))

summary_all_data %>% 
  group_by(allele) %>% 
  summarize(total = sum(unique_sites, na.rm = T)) -> all_regions

p <- ggplot(all_regions, aes(allele, total)) +
  geom_bar(stat = "identity") +
  scale_fill_manual() +
  scale_y_continuous(labels = comma) +
  ylab("Unique hyperedited reads") +
  theme(
    axis.title.x = element_blank(),
    axis.text.x = element_text(angle = 90,
                                 hjust = 1, vjust = 0.5),
    legend.title = element_blank()
    )
p

all_regions %>% 
  ungroup() %>% 
  mutate(total_sites = sum(total),
         percent_hyperedited_sites = 100 * total / total_sites)

# distribution across A_to_G alleles across states
summary_dat %>% 
  dplyr::filter(allele == "A->G") -> A_G_summary_dat

ggplot(A_G_summary_dat, aes(State, unique_sites)) +
  geom_bar(stat = "identity", aes(fill = State)) +
  scale_fill_manual(values = state_cols) +
  ylab("Unique hyperedited regions") +
  labs(title = "A to G hyperedited sites") + 
  facet_grid(~region) +
  theme(
    axis.text.x = element_blank()
  )
```

Overall the pattern for hyperedited regions or sites is similar. 


## How many reads support each editing site?

many of the identified editing sites are likely supported by a small number of reads, which could increase the noise in the data. Next we'll explore the relationship between read depth and number of sites. 

First determine number of reads per site and number of samples with site. 
```{r, cache = F}
edit_dat %>% 
  dplyr::group_by(allele, strand, chrom, start, end) %>% 
  summarize(reads = length(unique(id)),
            samples = length(unique(fileid))) -> read_count
  
ggplot(read_count, aes(reads)) +
  geom_density() +
  facet_wrap(~allele) +
  scale_x_log10() +
  labs(title = "number of reads supported editing site")

ggplot(read_count, aes(samples)) +
  geom_density() +
  facet_wrap(~allele) +
  scale_x_log10() +
  labs(title = "Number of samples with editing site")
```

These observations would suggest that requiring a site to be supported by more than 1 read could be beneficial. 

### Require 2 reads per site

```{r, count_reads_per_sites, cache = F}
edit_dat %>% 
  dplyr::group_by(allele, strand, chrom, start, end) %>% 
  mutate(supporting_reads = length(unique(id))) %>% 
  ungroup() -> edit_dat
```

```{r, filter_sites, cache = F}
dplyr::filter(edit_dat, 
              supporting_reads > 1) -> edit_dat_1            

summary_dat <- group_by(edit_dat_1, allele, region, State) %>% 
  dplyr::select("chrom", "start", "end", "strand") %>% 
  unique() %>% 
  summarize(unique_sites = n()) %>% 
  ungroup()

#add in groups with zero reads to complete allelic series
edit_dat %>% 
  group_by(allele, region, State) -> tmp
grps <- attr(tmp, "labels")
grps <- mutate(grps,
  unique_sites = 0
)
grps <- anti_join(grps, 
                  summary_dat,
                  by = c("region", "State", "allele"))

summary_dat <- bind_rows(summary_dat,
                         grps)
summary_dat <- mutate(summary_dat, 
                            State = factor(State,
                                           levels = state_order),
                      allele = str_replace(allele, "_to_", "->"))

p <- ggplot(summary_dat, aes(State, unique_sites)) +
  geom_bar(stat = "identity", aes(fill = State)) +
  scale_fill_manual(values = state_cols) +
  ylab("Unique hyperedited sites") +
  facet_grid(allele~region) +
  theme(
    axis.text.x = element_text(colour = state_cols),
    axis.title = element_text(size = 20),
    axis.title.x = element_blank(),
    strip.text = element_text(size = 20),
    legend.text = element_text(size = 16)
  )
p

save_plot("hyperedits/all_alleles_all_regions.pdf", p, 
          base_width = 8, base_height = 12)
```

```{r unique_sites_all_regions_states, cache = F}
summary_all_data <- group_by(edit_dat_1, allele) %>% 
  dplyr::select("chrom", "start", "end", "strand") %>% 
  unique() %>% 
  summarize(unique_sites = n()) %>% 
  ungroup()

#add in groups with zero reads to complete allelic series
edit_dat %>% 
  group_by(allele) -> tmp
grps <- attr(tmp, "labels")
grps <- mutate(grps,
  unique_sites = 0
)
grps <- anti_join(grps, 
                  summary_all_data,
                  by = c("allele"))

summary_all_data <- bind_rows(summary_all_data,
                         grps)
summary_all_data <- mutate(summary_all_data,
                      allele = str_replace(allele, "_to_", "->"))

summary_all_data %>% 
  group_by(allele) %>% 
  summarize(total = sum(unique_sites, na.rm = T)) -> all_regions

p <- ggplot(all_regions, aes(allele, total)) +
  geom_bar(stat = "identity") +
  scale_fill_manual() +
  scale_y_continuous(labels = comma) +
  ylab("Unique hyperedited sites") +
  theme(
    axis.title.x = element_blank(),
    axis.text.x = element_text(angle = 90,
                                 hjust = 1, vjust = 0.5),
    legend.title = element_blank()
    )
p
save_plot("hyperedits/all_sites.pdf", p)

all_regions %>% 
  ungroup() %>% 
  mutate(total_sites = sum(total),
         percent_hyperedited_sites = 100 * total / total_sites)
```

```{r, hyperedits_per_state, cache= F}

summary_dat <- group_by(edit_dat_1, animal_number, allele, region, State) %>% 
  dplyr::select("chrom", "start", "end", "strand") %>% 
  unique() %>% 
  summarize(unique_sites = n()) %>% 
  ungroup()

#add in groups with zero reads to complete allelic series
edit_dat %>% 
  group_by(allele, region, State) -> tmp
grps <- attr(tmp, "labels")
grps <- mutate(grps,
  unique_sites = 0
)
grps <- anti_join(grps, 
                  summary_dat,
                  by = c("region", "State", "allele"))

summary_dat <- bind_rows(summary_dat,
                         grps)
summary_dat <- mutate(summary_dat, 
                            State = factor(State,
                                           levels = state_order),
                      allele = str_replace(allele, "_to_", "->"))

# distribution across A_to_G alleles across states
summary_dat %>% 
  dplyr::filter(allele == "A->G") -> A_G_summary_dat

# compute normalized hyperedited sites based on library sizes
.dir <- file.path(data_dir, "star")
star_report_files <- dir(.dir, 
                         pattern = "*_2pass_Log.final.out",
                         recursive = T, full.names = T)

star_reports <- map(star_report_files, 
                    ~read_tsv(.x, col_names = F))

star_reports[[1]]

star_report_names <- basename(star_report_files) %>% 
  str_split(., "_", simplify = T) %>% 
  .[, 1] %>% 
  str_replace(., "^[0-9]+-", "")

names(star_reports) <- star_report_names
lib_sizes <- map(star_reports, 
                 ~dplyr::filter(.x, 
                                X1 == "Uniquely mapped reads number |") %>% 
                   dplyr::select(X2))

lib_sizes <- bind_rows(lib_sizes, .id = "animal_number") %>% 
  dplyr::rename(lib_size = X2) %>% 
  dplyr::mutate(lib_size = as.numeric(lib_size))

A_G_summary_dat <- left_join(A_G_summary_dat,
                             lib_sizes,
                             by = "animal_number")

A_G_summary_dat <- mutate(A_G_summary_dat,
                          normalized_sites = 1e6 * (unique_sites / lib_size))

# compute stats via ANOVA by region
A_G_stats <- group_by(A_G_summary_dat, region) %>% 
  do(broom::tidy(anova(lm(normalized_sites ~ State, data = .)))) %>% 
  dplyr::filter(term == "State") %>% 
  dplyr::mutate(p.value = signif(p.value, 2),
                p.value = paste0("p = ", p.value)) %>% 
  ungroup()

p <- ggplot(A_G_summary_dat, aes(State, normalized_sites)) +
  geom_boxplot(aes(fill = State),
               outlier.shape = NA) +
  geom_jitter() +
  geom_text(data = A_G_stats, aes(x = 3.5, 
                                  y = max(A_G_summary_dat$normalized_sites) * 1.1, 
                                  label = p.value)) +
  scale_fill_manual(values = state_cols) +
  ylab("Hyperedited sites \nper million mapped reads") +
  guides(fill = guide_legend(nrow = 1)) +
  facet_grid(~region) +
  theme(
    axis.text.x = element_text(colour = state_cols),
    axis.title.x = element_blank(),
    legend.position = "none"
  )
p

save_plot("hyperedits/ag_sites_per_state.pdf", p, base_width = 6)


p <- ggplot(A_G_summary_dat, aes(State, normalized_sites)) +
  geom_boxplot(aes(fill = State),
               outlier.shape = NA) +
  geom_jitter() +
  geom_text(data = A_G_stats, aes(x = 3.5, 
                                  y = max(A_G_summary_dat$normalized_sites) * 1.1, 
                                  label = p.value)) +
  ylim(c(0, max(A_G_summary_dat$normalized_sites) * 1.15)) +
  scale_fill_manual(values = state_cols) +
  ylab("Hyperedited sites \nper million mapped reads") +
  guides(fill = guide_legend(nrow = 1)) +
  facet_wrap(~region, nrow = 3) +
  theme(
    axis.text.x = element_text(colour = state_cols),
    axis.title.x = element_blank(),
    legend.position = "none"
  )
p
save_plot("hyperedits/ag_sites_per_state_vertical.pdf", p, base_width = 3, base_height = 5)


p <- ggplot(A_G_summary_dat, aes(State, normalized_sites)) +
#  geom_boxplot(aes(fill = State),
#               outlier.shape = NA) +
  geom_jitter(width = 0.25,
              aes(color = State)) +
  stat_summary(fun.y = "mean", 
               fun.ymin = "mean", 
               fun.ymax= "mean",
               size = 0.3,
               width = 0.75,
               geom = "crossbar") +
  geom_text(data = A_G_stats, aes(x = 3.5, 
                                  y = max(A_G_summary_dat$normalized_sites) * 1.1, 
                                  label = p.value)) +
  scale_colour_manual(values = state_cols) +
  ylab("Hyperedited sites \nper million mapped reads") +
  guides(fill = guide_legend(nrow = 1)) +
  facet_grid(~region) +
  theme(
    axis.text.x = element_text(colour = state_cols),
    axis.title.x = element_blank(),
    legend.position = "none"
  )
save_plot("hyperedits/ag_sites_per_state_mean_line.pdf", p, base_width = 6)
```

### next plot regions supported by at least two reads

```{r}
# keep reads from sites with at least two reads
read_dat %>% 
  dplyr::semi_join(edit_dat_1, by = "id") -> read_dat_1

# merge sites per allele per State per region
dplyr::group_by(read_dat_1, 
                State,
                allele,
                region,
                strand) %>% 
  valr::bed_merge(max_dist = 20) %>% 
  ungroup() -> hyper_clusters

summary_dat <- group_by(hyper_clusters, allele, region, State) %>% 
  dplyr::select("chrom", "start", "end", "strand") %>% 
  unique() %>% 
  summarize(unique_sites = n()) %>% 
  ungroup()

#add in groups with zero reads to complete allelic series
read_dat %>% 
  group_by(allele, region, State) -> tmp
grps <- attr(tmp, "labels")
grps <- mutate(grps,
  unique_sites = 0
)
grps <- anti_join(grps, 
                  summary_dat,
                  by = c("region", "State", "allele"))

summary_dat <- bind_rows(summary_dat,
                         grps)

summary_dat <- mutate(summary_dat, 
                            State = factor(State,
                                           levels = state_order),
                      allele = str_replace(allele, 
                                           "_to_", "->"))

p <- ggplot(summary_dat, aes(State, unique_sites)) +
  geom_bar(stat = "identity", aes(fill = State)) +
  scale_fill_manual(values = state_cols) +
  ylab("Unique hyperedited clusters") +
  facet_grid(allele~region) +
  theme(
    axis.text.x = element_text(colour = state_cols),
    axis.title = element_text(size = 20),
    axis.title.x = element_blank(),
    strip.text = element_text(size = 20),
    legend.text = element_text(size = 16)
  )
p
save_plot("hyperedits/all_alleles_all_regions_clusters.pdf", p, 
          base_width = 8, base_height = 12)
```
## Shared sites
Next we'll expore how many sites found in the warm samples are also found in the cold samples. 

```{r, fig.width = 10, fig.height = 10}
#first work with sites

AG_regions <- edit_dat_1 %>% 
  dplyr::select(State, strand, chrom, start, end) 

AG_regions <- split(AG_regions, 
                    AG_regions$State) %>% 
  map(., ~unique(.x) %>%  
        bed_sort())

AG_regions <- map(AG_regions, 
                  ~dplyr::mutate(.x, site = paste(chrom, 
                                              start, 
                                              end, 
                                              strand,
                                              sep = "::")) %>% 
                   dplyr::pull(site))

all_unique_sites <- unlist(AG_regions) %>%
  unname() %>% 
  unique()

lgl_df <- map_df(AG_regions,
                 ~all_unique_sites %in% .x)

#lgl_df <- lgl_df %>% dplyr::select(c(Ent, SA, SpD, IBA, LT, Ar))
lgl_df <- as.data.frame(lgl_df)

set.seed(20171010)
fit <- euler(lgl_df)  

pdf("hyperedits/allregions_shared_hyperedits.pdf")
plot(fit, 
     fill = state_cols,
     fill_opacity = 0.55,
     counts = list(cex = 1, col = "white"), 
     lwd = 3,
     cex = 2,   
     main = NULL,
     col = "black")
     #auto.key = list(space = "left", columns = 1))
dev.off() 

plot(fit, 
     fill = state_cols,
     fill_opacity = 0.55,
     counts = list(cex = 1, col = "white"), 
     lwd = 3,
     cex = 2,   
     main = NULL,
     col = "black")
```

### Extract out cold identified edits
  There is a set of sites that are found only in LT and Ar. Let's extract these out and examine their properties.
  
```{r}

# use logical dataframe from euler plot to 
#extract sites
lgl_df$site <- all_unique_sites
ar_lt_hyperedits <- dplyr::filter(lgl_df,
              Ar, 
              LT,
              !IBA, !SA, !SpD, !Ent)

# write to disk for now
write_tsv(ar_lt_hyperedits, 
          "hyperedits/hyperedited_sites_only_LT_Ar.txt")
```
## Comparison to sites detected by differential editing

Next, let's see how many hyperedited sites overlap with previously identified sites

```{r gdistribution_overlp}
hyper_edits <- dplyr::filter(edit_dat_1, allele == "A_to_G") %>% 
  mutate(site_id = paste(chrom, start, ifelse(strand == "+", 
                                              "A",
                                              "T"), sep = "::"))

gatk_sites <- read_tsv("edits/A_G_filtered_fdr0.01_sites_annotation_kmeans.txt.gz")
gatk_sites <- dplyr::select(gatk_sites, chrom, start, end, strand, site, EFF, FDR, GeneName:kmeans_cluster) %>% 
  unique() %>% 
  group_by(strand)

shared_sites <- inner_join(hyper_edits, gatk_sites, 
                           by = c("chrom", "start", 
                                  "end", "strand"))

```

There are `r length(unique(shared_sites$site))` hyperedited sites that are also in the list of sig sites identitifed by gatk/edgeR. There are `r length(unique(hyper_edits$site_id))` total sites identified as hyperedited.

Next check how many non-sig sites are found:

```{r gdistribution}
hyper_edits <- dplyr::filter(edit_dat_1, allele == "A_to_G") %>% 
  mutate(site_id = paste(chrom, start, ifelse(strand == "+", 
                                              "A",
                                              "T"), sep = "::"))

gatk_non_sigsites <- read_tsv("edits/A_G_filtered_notsignificant_sites_annotation_kmeans.txt.gz")
gatk_non_sigsites <- gatk_non_sigsites %>% 
  dplyr::select(chrom, start, end, strand, site, EFF, FDR, GeneName:ANNOTATED) %>% 
  unique() %>% 
  group_by(strand)

shared_sites <- inner_join(hyper_edits, gatk_non_sigsites, 
                           by = c("chrom", "start", "end", "strand"))

```


There are `r length(unique(shared_sites$site))` hyperedited sites that are also in the list of non-sig sites identitifed by gatk/edgeR. There are `r length(unique(hyper_edits$site_id))` total sites identified as hyperedited.


## Write out bed files

Lastly we'll write out the hyperedited sites to a vcf and bed file. The vcf will be pushed to tesla, and used to generate counts per position from the **aligned** reads, followed by edgeR editing site frequency testing. 

```{r make_vcf}
#vcf format
#chrom  pos (1bases)  ID  REF Alt QUAL  FILTER  INFO
# just make a pseudo-vcf, only need vcf format for get_pileup.py script
vcf_out <- dplyr::select(hyper_edits,
                         chrom, 
                         end, #1bases
                         site_id,
                         strand
                         ) %>% 
  unique()


bed_out <-  dplyr::mutate(hyper_edits,
                          name = ifelse(strand == "+",
                                        "strand_+",
                                        "strand_-")) %>% 
  dplyr::select(chrom, start, end, #1bases
                         name, site_id, strand ) %>% 
  dplyr::mutate_if(is.double, as.integer) %>% 
  ungroup() %>% 
  unique()
                         
vcf_out <- dplyr::mutate(vcf_out,
                         `#CHROM` = chrom,
                         POS = as.integer(end),
                         ID = ".",
                         REF = ifelse(strand == "+",
                                     "A",
                                     "T"),
                        ALT = ifelse(strand == "+",
                                     "G",
                                     "C"),
                        QUAL = 0.0,
                        FILTER = "PASS",
                        INFO = "AC=1",
                        FORMAT =  "GT:AD:DP:GQ:PL",
                        Dummy_sample = "1/1:0,2:2:6:1,6,0") %>% 
  ungroup() %>% 
  dplyr::select(-c(strand, chrom, end, site_id))

write_tsv(bed_out, "edits/hyperedited_sites.bed", col_names = T)
write_tsv(vcf_out, "edits/hyperedited_sites.vcf", col_names = T)


```
